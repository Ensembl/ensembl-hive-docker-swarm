Tips/reminders on running Hive experiments on Docker Swarm:

1. Make sure you don't have any docker swarm leftover from the times when dynamically allocated IPs were different.
    On the docker master run:
        docker swarm leave --force
    On the worker nodes run:
        docker swarm leave

2. Init a fresh swarm on the master:
    docker swarm init

3. Copy the command to join the swarm to the worker nodes and run it there

4. Take note of the last part of that connection command, change the port number from 2377 to 2375 and use this value to set DOCKER_MASTER_ADDR
    in all participating terminal windows - BOTH on master and worker nodes if you are planning to access both (which is a good idea).
   The master needs to have an extra config option set in /etc/default/docker: "-H tcp://0.0.0.0 -H unix:///var/run/docker.sock" . The first -H enables the IP server on *all* interfaces (if you remove 0.0.0.0 it only listens on localhost, and it won't be visible from the participating nodes). The second -H is to keep the standard UNIX server, needed by the docker CLI interface)

5. Refresh the hive docker image on all participating nodes - BOTH masters and workers:
    docker pull ensemblorg/ensembl-hive:dswarm

6. You may want to add ensembl-hive/scripts/dev to your PATH variable to simplify running ensembl-hive/scripts/dev/docker_jobs.pl

7. Make sure you create your hive database on a server that allows external access (check both MySQL server's config and your firewalls).

8. Make sure you use the public IP address in the URL for that database (neither "localhost" nor "127.0.0.1" will do) - test it.

9. You can run beekeeper.pl on any of the machines participating in the Swarm as long as you have set DOCKER_MASTER_ADDR variable there.
    It doesn't have to be the master node. In fact, I could not run the beekeeper.pl on master node in my experiments (Perl modules missing).

10. Run your beekeeper.pl , open a parallel database connection and watch the pipeline being worked on!
    Remember that the first analysis of LongMult pipeline is forced-LOCAL, so the first batch will have to (be able to) run locally!

11. If you want to restart, you may need to delete the services created by the previous attempt, as the service names have to be unique:
    $ docker service ls
        ID                  NAME                         MODE                REPLICAS            IMAGE                            PORTS
        quqiykcjmnhk        long_mult-Hive-default-2_1   replicated          0/4                 ensemblorg/ensembl-hive:dswarm   
        t0eundxn55m6        long_mult-Hive-default-1_2   replicated          0/4                 ensemblorg/ensembl-hive:dswarm   
        xi9f3ffbid5e        long_mult-Hive-default-1_3   replicated          0/2                 ensemblorg/ensembl-hive:dswarm  
    $ docker service rm long_mult-Hive-default-2_1 long_mult-Hive-default-1_2 long_mult-Hive-default-1_3

12. If/when services fail, you need to know the name of the service to find out what happened (you can't examine an individual worker, only a batch/service) :
    $ docker service ps long_mult-Hive-default-1_3
    $ docker service logs long_mult-Hive-default-1_3

13. When merging experimental/dswarm into master please remember to substitute all mentions of "experimental/dswarm" in the code as well!
    (at least once in Dockerfile and once in DockerSwarm.pm)

14. At the moment we cannot run beekeeper.pl itself in a Docker container, because of a schema constraint:
    beekeeper.process_id is currently forced to be an INTEGER, whereas worker.process_id is a VARCHAR, which is fine with DockerSwarm.

    However when/if the schema change from INTEGER to VARCHAR is made, the way to run beekeeper.pl as a Docker container service is this:

    docker service create --name long_mult_beekeeper1 --replicas 1 --restart-condition none --env DOCKER_MASTER_ADDR=$DOCKER_MASTER_ADDR --mount type=bind,source=/tmp/leo,destination=/tmp/leo --reserve-cpu 1 ensemblorg/ensembl-hive:dswarm  beekeeper.pl -url $EHIVE_URL -run

    Remember that at least with LongMult example the first analysis has to be run as LOCAL, and a Dockerized beekeeper doesn't know how to do it.
    So you can run one iteration manually outside of Docker, and then run the beekeeper service above. If it is run with "-run" option, you'll need
    to rescale it to 1 every time you want an iteration:
        docker service scale long_mult_beekeeper1=1
    It will go down to 0 after each iteration. This is something I would call "debug mode".
    When everything works, just switch it to "-loop -sleep 0.2" and enjoy.
    We really have to do something about DockerSwarm's inability to run Local workers though...
